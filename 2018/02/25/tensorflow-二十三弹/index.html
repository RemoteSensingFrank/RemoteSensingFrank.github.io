<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="随感，遥感，机器学习....想到什么写什么"><title>tensorflow-二十三弹 | 吴蔚</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">tensorflow-二十三弹</h1><a id="logo" href="/.">吴蔚</a><p class="description">生命不息，折腾不止！</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">tensorflow-二十三弹</h1><div class="post-meta">Feb 25, 2018<span> | </span><span class="category"><a href="/categories/学习/">学习</a></span></div><a class="disqus-comment-count" href="/2018/02/25/tensorflow-二十三弹/#vcomment"><span class="valine-comment-count" data-xid="/2018/02/25/tensorflow-二十三弹/"></span><span> 条评论</span></a><div class="post-content"><p>今天就tensorflow训练好的模型的存取问题进行一些讨论，主要翻译了一下一篇英文博客，另外加上了一些自己的尝试和处理经验，英文博客的地址为：<a href="http://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/" target="_blank" rel="noopener">http://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/</a>　这个是官方的一个说明，我先翻译这个文章，如果英文好的可以直接跳过，主要内容为：<br>文章主要分为四个部分，第一个部分的介绍我们不进行翻译，相信对tensorflow有基本了解的同学都能懂，另外前几篇博客中都有介绍，我直接从第二个部分开始翻译：</p>
<h2 id="２．tensorflow模型的保存"><a href="#２．tensorflow模型的保存" class="headerlink" title="２．tensorflow模型的保存"></a>２．tensorflow模型的保存</h2><p>我们说如果对于一个图像分类的应用，训练了一个卷积神经网络．在训练的过程中我们可以查看loss和accuracy变量，一旦训练完成则可以手动停止训练过程，或者参数不再变化后停止训练过程．当训练完成后需要将训练结果保存起来以便于以后进行应用，而在tensorflow中如果你希望保存整个网络图和所有变量，我们需要创建一个tf.train.Saver()类的实例，如下：<br>saver = tf.train.Saver()<br>记住，tensorflow的变量只有在session中才被激活，因此如果希望保存图，则必须要在session中调用创建的saver变量<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.Saver()</span><br><span class="line">saver.save(sess, <span class="string">'my-test-model'</span>)</span><br></pre></td></tr></table></figure></p>
<p>在这里，sess是session的一个对象，‘my-test-model’是你想保存模型的文件名，下面是完整的代码示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">w1 = tf.Variable(tf.random_normal(shape=[<span class="number">2</span>]), name=<span class="string">'w1'</span>)</span><br><span class="line">w2 = tf.Variable(tf.random_normal(shape=[<span class="number">5</span>]), name=<span class="string">'w2'</span>)</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">saver.save(sess, <span class="string">'my_test_model'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This will save following files in Tensorflow v &gt;= 0.11</span></span><br><span class="line"><span class="comment"># my_test_model.data-00000-of-00001</span></span><br><span class="line"><span class="comment"># my_test_model.index</span></span><br><span class="line"><span class="comment"># my_test_model.meta</span></span><br><span class="line"><span class="comment"># checkpoint</span></span><br></pre></td></tr></table></figure></p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">w1 = tf.Variable(tf.random_normal(shape=[<span class="number">2</span>]), name=<span class="string">'w1'</span>)</span><br><span class="line">w2 = tf.Variable(tf.random_normal(shape=[<span class="number">5</span>]), name=<span class="string">'w2'</span>)</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">saver.save(sess, <span class="string">'my_test_model'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This will save following files in Tensorflow v &gt;= 0.11</span></span><br><span class="line"><span class="comment"># my_test_model.data-00000-of-00001</span></span><br><span class="line"><span class="comment"># my_test_model.index</span></span><br><span class="line"><span class="comment"># my_test_model.meta</span></span><br><span class="line"><span class="comment"># checkpoint</span></span><br></pre></td></tr></table></figure>
<p>如果我们想在模型训练一千次后将模型保存，我们可以通过如下代码实现：<br>saver.save(sess, ‘my_test_model’,global_step=1000)<br>以上代码会在模型名称后添加‘-1000’的后缀，另外如下文件将会被创建：</p>
<p>my_test_model-1000.index<br>my_test_model-1000.meta<br>my_test_model-1000.data-00000-of-00001<br>checkpoint  </p>
<p>my_test_model-1000.index<br>my_test_model-1000.meta<br>my_test_model-1000.data-00000-of-00001<br>checkpoint  </p>
<p>在训练过程中我们希望每迭代1000次就保存一次模型，但是.meta文件只会在最开始被创建一次，我们不需要多次创建，我们只需要将最近一次的迭代参数写入文件中，当我们不想将训练参数写入文件中时我们可以通过如下代码实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">saver.save(sess, <span class="string">'my-model'</span>, global_step=step,write_meta_graph=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">saver.save(sess, <span class="string">'my-model'</span>, global_step=step,write_meta_graph=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></p>
<p>If you want to keep only 4 latest models and want to save one model after every 2 hours during training you can use max_to_keep and keep_checkpoint_every_n_hours like this.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#saves a model every 2 hours and maximum 4 latest models are saved.</span></span><br><span class="line">saver = tf.train.Saver(max_to_keep=<span class="number">4</span>, keep_checkpoint_every_n_hours=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#saves a model every 2 hours and maximum 4 latest models are saved.</span></span><br><span class="line">saver = tf.train.Saver(max_to_keep=<span class="number">4</span>, keep_checkpoint_every_n_hours=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>注意，我们在保存过程中没有对任何变量进行指定，在这样的情况下会保存所有变量，如果我们不想保存所有变量，我们可以在创建实例的时候指出哪些变量是需要保存的，示例代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">w1 = tf.Variable(tf.random_normal(shape=[<span class="number">2</span>]), name=<span class="string">'w1'</span>)</span><br><span class="line">w2 = tf.Variable(tf.random_normal(shape=[<span class="number">5</span>]), name=<span class="string">'w2'</span>)</span><br><span class="line">saver = tf.train.Saver([w1,w2])</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">saver.save(sess, <span class="string">'my_test_model'</span>,global_step=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure></p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">w1 = tf.Variable(tf.random_normal(shape=[<span class="number">2</span>]), name=<span class="string">'w1'</span>)</span><br><span class="line">w2 = tf.Variable(tf.random_normal(shape=[<span class="number">5</span>]), name=<span class="string">'w2'</span>)</span><br><span class="line">saver = tf.train.Saver([w1,w2])</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">saver.save(sess, <span class="string">'my_test_model'</span>,global_step=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<p>通过以上方法可以指定graph中所有部分的变量</p>
<h2 id="3-导入训练好的模型"><a href="#3-导入训练好的模型" class="headerlink" title="3. 导入训练好的模型:"></a>3. 导入训练好的模型:</h2><p>如果你想使用他人训练好的模型，你需要做以下两件事情：<br>a) 创建网络网络:<br>你可以通过编写python代码手动创建与原始模型一样的网络，或者如果你觉得这么做太麻烦，由于我们将网络结构已经保存在meta文件中，因此我们可以直接导入网络模型：<br>saver = tf.train.import_meta_graph(‘my_test_model-1000.meta’)<br>记住，在.meta文件中只保存了网络结构，因此在导入网络后还需要加载在图中训练的参数</p>
<p>b) 加载模型参数:<br>我们在保存网络的过程中也保存了网络参数，因此我们可以通过tf.train.Saver()类的实例来读取神经网络的参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  new_saver = tf.train.import_meta_graph(<span class="string">'my_test_model-1000.meta'</span>)</span><br><span class="line">  new_saver.restore(sess, tf.train.latest_checkpoint(<span class="string">'./'</span>))</span><br></pre></td></tr></table></figure>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  new_saver = tf.train.import_meta_graph(<span class="string">'my_test_model-1000.meta'</span>)</span><br><span class="line">  new_saver.restore(sess, tf.train.latest_checkpoint(<span class="string">'./'</span>))</span><br></pre></td></tr></table></figure>
<p>加载参数后我们如果想要获取某一个张量可以通过如下代码实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:    </span><br><span class="line">    saver = tf.train.import_meta_graph(<span class="string">'my-model-1000.meta'</span>)</span><br><span class="line">    saver.restore(sess,tf.train.latest_checkpoint(<span class="string">'./'</span>))</span><br><span class="line">    print(sess.run(<span class="string">'w1:0'</span>))</span><br><span class="line"><span class="comment">##Model has been restored. Above statement will print the saved value of w1.</span></span><br></pre></td></tr></table></figure></p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:    </span><br><span class="line">    saver = tf.train.import_meta_graph(<span class="string">'my-model-1000.meta'</span>)</span><br><span class="line">    saver.restore(sess,tf.train.latest_checkpoint(<span class="string">'./'</span>))</span><br><span class="line">    print(sess.run(<span class="string">'w1:0'</span>))</span><br><span class="line"><span class="comment">##Model has been restored. Above statement will print the saved value of w1.</span></span><br></pre></td></tr></table></figure>
<p>到目前为止，你已经了解了如何保存和导入tensorflow的模型，在下一章中会详细说明如何去使用和加载训练号的模型</p>
<h2 id="4-加载训练好的模型的实例"><a href="#4-加载训练好的模型的实例" class="headerlink" title="4. 加载训练好的模型的实例"></a>4. 加载训练好的模型的实例</h2><p>现在你应该已经知道如何保存和加载模型了，我们进一步说明如何加载训练好的模型以及如何通过模型进行预测，拟合或通过模型进行进一步的训练．在使用tensorflow训练的过程中定义的计算图中包括训练数据以及一些高维变量如学习率，训练步数等．标准的做法是所有变量都使用placeholders来定义，我们首先创建一个网络然后保存网络，网络保存后placeholders定义的变量的值不会被存储</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#Prepare to feed input, i.e. feed_dict and placeholders</span></span><br><span class="line">w1 = tf.placeholder(<span class="string">"float"</span>, name=<span class="string">"w1"</span>)</span><br><span class="line">w2 = tf.placeholder(<span class="string">"float"</span>, name=<span class="string">"w2"</span>)</span><br><span class="line">b1= tf.Variable(<span class="number">2.0</span>,name=<span class="string">"bias"</span>)</span><br><span class="line">feed_dict =&#123;w1:<span class="number">4</span>,w2:<span class="number">8</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Define a test operation that we will restore</span></span><br><span class="line">w3 = tf.add(w1,w2)</span><br><span class="line">w4 = tf.multiply(w3,b1,name=<span class="string">"op_to_restore"</span>)</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line"><span class="comment">#Create a saver object which will save all the variables</span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="comment">#Run the operation by feeding input</span></span><br><span class="line"><span class="keyword">print</span> sess.run(w4,feed_dict)</span><br><span class="line"><span class="comment">#Prints 24 which is sum of (w1+w2)*b1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Now, save the graph</span></span><br><span class="line">saver.save(sess, <span class="string">'my_test_model'</span>,global_step=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#Prepare to feed input, i.e. feed_dict and placeholders</span></span><br><span class="line">w1 = tf.placeholder(<span class="string">"float"</span>, name=<span class="string">"w1"</span>)</span><br><span class="line">w2 = tf.placeholder(<span class="string">"float"</span>, name=<span class="string">"w2"</span>)</span><br><span class="line">b1= tf.Variable(<span class="number">2.0</span>,name=<span class="string">"bias"</span>)</span><br><span class="line">feed_dict =&#123;w1:<span class="number">4</span>,w2:<span class="number">8</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Define a test operation that we will restore</span></span><br><span class="line">w3 = tf.add(w1,w2)</span><br><span class="line">w4 = tf.multiply(w3,b1,name=<span class="string">"op_to_restore"</span>)</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line"><span class="comment">#Create a saver object which will save all the variables</span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="comment">#Run the operation by feeding input</span></span><br><span class="line"><span class="keyword">print</span> sess.run(w4,feed_dict)</span><br><span class="line"><span class="comment">#Prints 24 which is sum of (w1+w2)*b1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Now, save the graph</span></span><br><span class="line">saver.save(sess, <span class="string">'my_test_model'</span>,global_step=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<p>现在当我们想要保存模型的时候我们只需要保存图和权重，另外准备一个新的feed_dict就可以使用心得数据训练网络了，另外我们也可以获取到村包的操作和placeholder变量通过graph.get_tensor_by_name()方法</p>
<ul>
<li><p>How to access saved variable/Tensor/placeholders</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w1 = graph.get_tensor_by_name(<span class="string">"w1:0"</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>How to access saved operation</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">op_to_restore = graph.get_tensor_by_name(<span class="string">"op_to_restore:0"</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>How to access saved variable/Tensor/placeholders</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w1 = graph.get_tensor_by_name(<span class="string">"w1:0"</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>How to access saved operation</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">op_to_restore = graph.get_tensor_by_name(<span class="string">"op_to_restore:0"</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>如果我们只是想对于不同的训练数据使用模型训练，则我们只需要简单的通过feed_dict传递参数就好了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">sess=tf.Session()    </span><br><span class="line"><span class="comment">#First let's load meta graph and restore weights</span></span><br><span class="line">saver = tf.train.import_meta_graph(<span class="string">'my_test_model-1000.meta'</span>)</span><br><span class="line">saver.restore(sess,tf.train.latest_checkpoint(<span class="string">'./'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, let's access and create placeholders variables and</span></span><br><span class="line"><span class="comment"># create feed-dict to feed new data</span></span><br><span class="line"></span><br><span class="line">graph = tf.get_default_graph()</span><br><span class="line">w1 = graph.get_tensor_by_name(<span class="string">"w1:0"</span>)</span><br><span class="line">w2 = graph.get_tensor_by_name(<span class="string">"w2:0"</span>)</span><br><span class="line">feed_dict =&#123;w1:<span class="number">13.0</span>,w2:<span class="number">17.0</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Now, access the op that you want to run.</span></span><br><span class="line">op_to_restore = graph.get_tensor_by_name(<span class="string">"op_to_restore:0"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> sess.run(op_to_restore,feed_dict)</span><br><span class="line"><span class="comment">#This will print 60 which is calculated</span></span><br><span class="line"><span class="comment">#using new values of w1 and w2 and saved value of b1.</span></span><br></pre></td></tr></table></figure>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">sess=tf.Session()    </span><br><span class="line"><span class="comment">#First let's load meta graph and restore weights</span></span><br><span class="line">saver = tf.train.import_meta_graph(<span class="string">'my_test_model-1000.meta'</span>)</span><br><span class="line">saver.restore(sess,tf.train.latest_checkpoint(<span class="string">'./'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, let's access and create placeholders variables and</span></span><br><span class="line"><span class="comment"># create feed-dict to feed new data</span></span><br><span class="line"></span><br><span class="line">graph = tf.get_default_graph()</span><br><span class="line">w1 = graph.get_tensor_by_name(<span class="string">"w1:0"</span>)</span><br><span class="line">w2 = graph.get_tensor_by_name(<span class="string">"w2:0"</span>)</span><br><span class="line">feed_dict =&#123;w1:<span class="number">13.0</span>,w2:<span class="number">17.0</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Now, access the op that you want to run.</span></span><br><span class="line">op_to_restore = graph.get_tensor_by_name(<span class="string">"op_to_restore:0"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> sess.run(op_to_restore,feed_dict)</span><br><span class="line"><span class="comment">#This will print 60 which is calculated</span></span><br><span class="line"><span class="comment">#using new values of w1 and w2 and saved value of b1.</span></span><br></pre></td></tr></table></figure>
<p>如果你需要在原始的模型基础上添加更多的操作，添加更多层进行重新训练，则代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">sess=tf.Session()    </span><br><span class="line"><span class="comment">#First let's load meta graph and restore weights</span></span><br><span class="line">saver = tf.train.import_meta_graph(<span class="string">'my_test_model-1000.meta'</span>)</span><br><span class="line">saver.restore(sess,tf.train.latest_checkpoint(<span class="string">'./'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">* Now, let<span class="string">'s access and create placeholders variables and</span></span><br><span class="line"><span class="string">* create feed-dict to feed new data</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">graph = tf.get_default_graph()</span></span><br><span class="line"><span class="string">w1 = graph.get_tensor_by_name("w1:0")</span></span><br><span class="line"><span class="string">w2 = graph.get_tensor_by_name("w2:0")</span></span><br><span class="line"><span class="string">feed_dict =&#123;w1:13.0,w2:17.0&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">* Now, access the op that you want to run.</span></span><br><span class="line"><span class="string">op_to_restore = graph.get_tensor_by_name("op_to_restore:0")</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">* Add more to the current graph</span></span><br><span class="line"><span class="string">add_on_op = tf.multiply(op_to_restore,2)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">print sess.run(add_on_op,feed_dict)</span></span><br><span class="line"><span class="string">* This will print 120.</span></span><br></pre></td></tr></table></figure></p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">sess=tf.Session()    </span><br><span class="line">* First let<span class="string">'s load meta graph and restore weights</span></span><br><span class="line"><span class="string">saver = tf.train.import_meta_graph('</span>my_test_model<span class="number">-1000.</span>meta<span class="string">')</span></span><br><span class="line"><span class="string">saver.restore(sess,tf.train.latest_checkpoint('</span>./<span class="string">'))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">* Now, let'</span>s access <span class="keyword">and</span> create placeholders variables <span class="keyword">and</span></span><br><span class="line">* create feed-dict to feed new data</span><br><span class="line"></span><br><span class="line">graph = tf.get_default_graph()</span><br><span class="line">w1 = graph.get_tensor_by_name(<span class="string">"w1:0"</span>)</span><br><span class="line">w2 = graph.get_tensor_by_name(<span class="string">"w2:0"</span>)</span><br><span class="line">feed_dict =&#123;w1:<span class="number">13.0</span>,w2:<span class="number">17.0</span>&#125;</span><br><span class="line"></span><br><span class="line">* Now, access the op that you want to run.</span><br><span class="line">op_to_restore = graph.get_tensor_by_name(<span class="string">"op_to_restore:0"</span>)</span><br><span class="line"></span><br><span class="line">* Add more to the current graph</span><br><span class="line">add_on_op = tf.multiply(op_to_restore,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> sess.run(add_on_op,feed_dict)</span><br><span class="line">* This will <span class="keyword">print</span> <span class="number">120.</span></span><br></pre></td></tr></table></figure>
<p>另外你也可以保存部分就的网络结构并添加新的结构去训练更好的网络<br>……<br>……<br>saver = tf.train.import_meta_graph(‘vgg.meta’)</p>
<ul>
<li>Access the graph<br>graph = tf.get_default_graph()</li>
<li><p>Prepare the feed_dict for feeding data for fine-tuning</p>
</li>
<li><p>Access the appropriate output for fine-tuning<br>fc7= graph.get_tensor_by_name(‘fc7:0’)</p>
</li>
<li><p>use this if you only want to change gradients of the last layer</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">fc7 = tf.stop_gradient(fc7) <span class="comment"># It's an identity function</span></span><br><span class="line">fc7_shape= fc7.get_shape().as_list()</span><br><span class="line"></span><br><span class="line">new_outputs=<span class="number">2</span></span><br><span class="line">weights = tf.Variable(tf.truncated_normal([fc7_shape[<span class="number">3</span>], num_outputs], stddev=<span class="number">0.05</span>))</span><br><span class="line">biases = tf.Variable(tf.constant(<span class="number">0.05</span>, shape=[num_outputs]))</span><br><span class="line">output = tf.matmul(fc7, weights) + biases</span><br><span class="line">pred = tf.nn.softmax(output)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, you run this with fine-tuning data in sess.run()</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>……<br>……<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.import_meta_graph(<span class="string">'vgg.meta'</span>)</span><br></pre></td></tr></table></figure></p>
<p>Access the graph<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">* graph = tf.get_default_graph()</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>Prepare the feed_dict for feeding data for fine-tuning</p>
</li>
<li><p>Access the appropriate output for fine-tuning</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fc7= graph.get_tensor_by_name(<span class="string">'fc7:0'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>use this if you only want to change gradients of the last layer</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">fc7 = tf.stop_gradient(fc7) <span class="comment"># It's an identity function</span></span><br><span class="line">fc7_shape= fc7.get_shape().as_list()</span><br><span class="line"></span><br><span class="line">new_outputs=<span class="number">2</span></span><br><span class="line">weights = tf.Variable(tf.truncated_normal([fc7_shape[<span class="number">3</span>], num_outputs], stddev=<span class="number">0.05</span>))</span><br><span class="line">biases = tf.Variable(tf.constant(<span class="number">0.05</span>, shape=[num_outputs]))</span><br><span class="line">output = tf.matmul(fc7, weights) + biases</span><br><span class="line">pred = tf.nn.softmax(output)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, you run this with fine-tuning data in sess.run()</span></span><br></pre></td></tr></table></figure>
<p>以上就是全部翻译，但是在实际处理过程中遇到了一些问题，实际上在深度学习的应用过程中我们的变量可能定义如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'input'</span>):</span><br><span class="line">    x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>],name = <span class="string">'x-input'</span>)</span><br><span class="line">    y = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>, <span class="number">10</span>],name=<span class="string">'y-input'</span>)</span><br><span class="line">    x_image = tf.reshape(x,[<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>],name=<span class="string">'img'</span>)</span><br><span class="line">    tf.summary.image(<span class="string">'image'</span>,x_image,<span class="number">20</span>)</span><br></pre></td></tr></table></figure></p>
<p>通过with结构进行区分，在此情况下get_tensor_by_name函数获取变量的过程中需要添加上with的结构进行区分，否则无法获取到变量．整个tensorflow模型的保存和加载就介绍如下．</p>
</div><div class="tags"><a href="/tags/tensorflow学习/">tensorflow学习</a></div><div class="post-nav"><a class="pre" href="/2018/02/28/tensorflow－二十四弹/">tensorflow－二十四弹</a><a class="next" href="/2018/02/25/新年/">新年</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'true' == true ? true : false;
var verify = 'true' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'uHNJtTxLkcGm3VRtuRGk53hb-gzGzoHsz',
  appKey:'h8s1QFO2dLQ62H0axpKB6WnD',
  placeholder:'说点啥吧...',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"><input type="hidden" name="si" value="http://www.wuweiblog.com"><input name="tn" type="hidden" value="bds"><input name="cl" type="hidden" value="3"><input name="ct" type="hidden" value="2097152"><input name="s" type="hidden" value="on"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/书评/">书评</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/图像处理/">图像处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/学习/">学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/小说/">小说</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/影评/">影评</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学/">数学</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/游戏/">游戏</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/点云处理/">点云处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随感/">随感</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/ArcGIS，前端开发/" style="font-size: 15px;">ArcGIS，前端开发</a> <a href="/tags/ArcGIS环境配置/" style="font-size: 15px;">ArcGIS环境配置</a> <a href="/tags/ArcGIS开发/" style="font-size: 15px;">ArcGIS开发</a> <a href="/tags/开发/" style="font-size: 15px;">开发</a> <a href="/tags/linux-学习/" style="font-size: 15px;">linux 学习</a> <a href="/tags/学习/" style="font-size: 15px;">学习</a> <a href="/tags/数学/" style="font-size: 15px;">数学</a> <a href="/tags/图像处理数学原理/" style="font-size: 15px;">图像处理数学原理</a> <a href="/tags/系统架构-学习/" style="font-size: 15px;">系统架构 学习</a> <a href="/tags/效率/" style="font-size: 15px;">效率</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/机器学习，图像处理/" style="font-size: 15px;">机器学习，图像处理</a> <a href="/tags/tensorflow学习/" style="font-size: 15px;">tensorflow学习</a> <a href="/tags/随感/" style="font-size: 15px;">随感</a> <a href="/tags/Mary-and-Max，影评/" style="font-size: 15px;">Mary and Max，影评</a> <a href="/tags/断舍离，书评/" style="font-size: 15px;">断舍离，书评</a> <a href="/tags/沉默的大多数，书评/" style="font-size: 15px;">沉默的大多数，书评</a> <a href="/tags/呼兰河传-书评/" style="font-size: 15px;">呼兰河传,书评</a> <a href="/tags/雪中悍刀行-书评/" style="font-size: 15px;">雪中悍刀行,书评</a> <a href="/tags/将夜-书评/" style="font-size: 15px;">将夜,书评</a> <a href="/tags/中国经济2019-时间的答案/" style="font-size: 15px;">中国经济2019,时间的答案</a> <a href="/tags/潜规则-书评/" style="font-size: 15px;">潜规则,书评</a> <a href="/tags/未来简史-书评/" style="font-size: 15px;">未来简史,书评</a> <a href="/tags/熊镇-书评/" style="font-size: 15px;">熊镇,书评</a> <a href="/tags/图像处理/" style="font-size: 15px;">图像处理</a> <a href="/tags/你好疯子，影评/" style="font-size: 15px;">你好疯子，影评</a> <a href="/tags/openMVG-openMVS学习/" style="font-size: 15px;">openMVG openMVS学习</a> <a href="/tags/喜剧之王，影评/" style="font-size: 15px;">喜剧之王，影评</a> <a href="/tags/The-Legend-of-1900/" style="font-size: 15px;">The Legend of 1900</a> <a href="/tags/随感-摄影测量/" style="font-size: 15px;">随感-摄影测量</a> <a href="/tags/随感，毕业/" style="font-size: 15px;">随感，毕业</a> <a href="/tags/校正方法，控制点，光束法平差/" style="font-size: 15px;">校正方法，控制点，光束法平差</a> <a href="/tags/linux学习/" style="font-size: 15px;">linux学习</a> <a href="/tags/月亮与六便士/" style="font-size: 15px;">月亮与六便士</a> <a href="/tags/电影十二公民/" style="font-size: 15px;">电影十二公民</a> <a href="/tags/小说/" style="font-size: 15px;">小说</a> <a href="/tags/随感，死亡/" style="font-size: 15px;">随感，死亡</a> <a href="/tags/V字仇杀队-浪潮，影评/" style="font-size: 15px;">V字仇杀队,浪潮，影评</a> <a href="/tags/指环王，这个杀手不太冷/" style="font-size: 15px;">指环王，这个杀手不太冷</a> <a href="/tags/随感－代码重构/" style="font-size: 15px;">随感－代码重构</a> <a href="/tags/遗愿清单，影评/" style="font-size: 15px;">遗愿清单，影评</a> <a href="/tags/R-学习/" style="font-size: 15px;">R 学习</a> <a href="/tags/点云处理/" style="font-size: 15px;">点云处理</a> <a href="/tags/爱乐之城，影评/" style="font-size: 15px;">爱乐之城，影评</a> <a href="/tags/狗子日记/" style="font-size: 15px;">狗子日记</a> <a href="/tags/一个叫欧维的男人决定去死，书评/" style="font-size: 15px;">一个叫欧维的男人决定去死，书评</a> <a href="/tags/星际穿越，影评/" style="font-size: 15px;">星际穿越，影评</a> <a href="/tags/图像处理的数学原理/" style="font-size: 15px;">图像处理的数学原理</a> <a href="/tags/共产党宣言/" style="font-size: 15px;">共产党宣言</a> <a href="/tags/社交网络，影评/" style="font-size: 15px;">社交网络，影评</a> <a href="/tags/秒速五厘米/" style="font-size: 15px;">秒速五厘米</a> <a href="/tags/海涛之声，影评/" style="font-size: 15px;">海涛之声，影评</a> <a href="/tags/饥荒/" style="font-size: 15px;">饥荒</a> <a href="/tags/白日梦想家，影评/" style="font-size: 15px;">白日梦想家，影评</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2021/01/31/社会与资本/">社会与资本</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/25/有那么一瞬间/">有那么一瞬间</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/06/死亡记录/">死亡记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/06/不读书-九/">不读书(九)</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/16/挣扎/">挣扎</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/02/点到三维空间直线距离计算以向量方式计算/">点到三维空间直线距离计算以向量方式计算</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/30/ArcGIS-结合-WebGL动态渲染1/">ArcGIS 结合 WebGL动态渲染1</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/30/狗子日记十一月四号/">狗子日记十一月四号</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/18/点云处理总结/">点云处理总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/05/社会青年/">社会青年</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/RemoteSensingFrank" title="Github" target="_blank">Github</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">吴蔚.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>