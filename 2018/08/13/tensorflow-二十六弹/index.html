<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="随感，遥感，机器学习....想到什么写什么"><title>tensorflow-二十六弹 | 吴蔚</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">tensorflow-二十六弹</h1><a id="logo" href="/.">吴蔚</a><p class="description">生命不息，折腾不止！</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">tensorflow-二十六弹</h1><div class="post-meta">Aug 13, 2018<span> | </span><span class="category"><a href="/categories/学习/">学习</a></span></div><a class="disqus-comment-count" href="/2018/08/13/tensorflow-二十六弹/#vcomment"><span class="valine-comment-count" data-xid="/2018/08/13/tensorflow-二十六弹/"></span><span> 条评论</span></a><div class="post-content"><p>&nbsp;&nbsp;&nbsp;&nbsp;写了很多关于tensorflow的部分，但是都比较零散，因为以前不管是对于python还是对于机器学习都了解得不够深刻，因此写出来的东西也就显得比较零散，代码不能够构成一个体系，所以也就谈不上什么积累，不过是多了解了一些关于tensorflow的东西而已，现在不管是对于python还是对于深度学习都有了更加深刻的理解，所以准备重新对整个过程进行组织，代码进行更加有条理的重构，以便于进行进一步的扩展。<br>&nbsp;&nbsp;目前只搭了一个CNN的框架，整个构架描述为：</p>
<ul>
<li>1.定义神经网络的基本结构单元：</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;实际上神经所有的神经网络都会有一些基本的结构体，如权重，如偏置；因为就目前来说神经网络就是n多的拟合线性运算加上一个响应函数进行拟合，所以基本的结构单元都是相似的，因此我们定义了一个神经网络基类来初始化这些基础的结构<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment">#基础网络功能，包括：</span></span><br><span class="line"><span class="comment">#1.权重定义</span></span><br><span class="line"><span class="comment">#2.增益的定义</span></span><br><span class="line"><span class="comment">#3.二维卷积运算</span></span><br><span class="line"><span class="comment">#4.最大值池化</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseNet</span>:</span></span><br><span class="line">    <span class="comment">#初始化权重</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(self,shape)</span>:</span></span><br><span class="line">        <span class="comment">#从截断的正态分布中输出随机值</span></span><br><span class="line">        initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</span><br><span class="line">        <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#初始化偏置</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(self,shape)</span>:</span></span><br><span class="line">        <span class="comment">#设置常数为0.1</span></span><br><span class="line">        initial = tf.constant(<span class="number">0.1</span>, shape=shape)</span><br><span class="line">        <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#二维卷积运算</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(self,x, W)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>], padding=<span class="string">"SAME"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最大值池化</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">                              strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>], padding=<span class="string">"SAME"</span>)</span><br></pre></td></tr></table></figure></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;从上面的代码中可以看到，我们定义的结构体包括：1.权重变量的定义；2.偏置变量的定义；3.卷积运算；4.池化操作；实际上卷积运算不是所有神经网络通用的操作，仅仅是卷积神经网络需要的操作，但是我们目前就是处理卷积神经网络，为了方便就这么写了。  </p>
<ul>
<li>2.特殊网络结构的定义：</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;定义好了基本的神经网络结构以后剩下的工作就是针对某一个神经网络进行特殊的定义，目前我们只定义了卷积神经网络，实际上卷神经网络相对比较简单，主要的结构有两个部分，第一个是卷积层，通过卷积层可以进行参数共享从而减小参数个数，另外通过不同的卷积核实际上可以提取不同的特征从而对目标进行识别，另外一个是池化操作，池化操作是神经网络的一个巨大创新，通过池化这个简单的操作对近邻的特征进行概括，并且通过池化操作可以得到待识别目标的旋转不变特征。</p>
<ul>
<li><ol start="3">
<li>根据数据对网络进行实例化：</li>
</ol>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#-*- coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"../data/MNIST_data/"</span>,one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">ckptfiles = <span class="string">'./mnist_LeNet_ckpt/'</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">mnistLeNet</span><span class="params">(LeNet)</span>:</span></span><br><span class="line">    <span class="comment">#初始化网络</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        LeNet.__init__(self,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#控制变量定义</span></span><br><span class="line">        self.learning_rate = <span class="number">0.001</span></span><br><span class="line">        <span class="comment"># 记录已经训练的次数</span></span><br><span class="line">        self.global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="keyword">False</span>)</span><br><span class="line">        self.x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>])</span><br><span class="line">        self.label = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>])</span><br><span class="line">        self.x_image = tf.reshape(self.x, [<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#网路层次定义</span></span><br><span class="line">        self.layer1(<span class="number">5</span>,<span class="number">5</span>,<span class="number">32</span>)</span><br><span class="line">        self.layer2(<span class="number">5</span>,<span class="number">5</span>,<span class="number">64</span>)</span><br><span class="line">        self.fullConnLayer(int(<span class="number">1024</span>))</span><br><span class="line">        self.outputLayer(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#计算参数定义</span></span><br><span class="line">        <span class="comment">#loss</span></span><br><span class="line">        self.loss = -tf.reduce_sum(self.label * tf.log(self.y + <span class="number">1e-10</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># minimize 可传入参数 global_step， 每次训练 global_step的值会增加1</span></span><br><span class="line">        <span class="comment"># 因此，可以通过计算self.global_step这个张量的值，知道当前训练了多少步</span></span><br><span class="line">        self.train = tf.train.AdamOptimizer(self.learning_rate).minimize(</span><br><span class="line">            self.loss, global_step=self.global_step)</span><br><span class="line"></span><br><span class="line">        predict = tf.equal(tf.argmax(self.label, <span class="number">1</span>), tf.argmax(self.y, <span class="number">1</span>))</span><br><span class="line">        self.accuracy = tf.reduce_mean(tf.cast(predict, <span class="string">"float"</span>))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TrainMnistLeNet</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.net = mnistLeNet()</span><br><span class="line">        self.sess = tf.Session()</span><br><span class="line">        self.sess.run(tf.global_variables_initializer())</span><br><span class="line">        self.data = mnist</span><br><span class="line"></span><br><span class="line">    <span class="comment">#模型训练过程</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">trainMnist</span><span class="params">(self)</span>:</span></span><br><span class="line">        batch_size = <span class="number">50</span></span><br><span class="line">        train_step = <span class="number">3000</span></span><br><span class="line">        <span class="comment"># 记录训练次数, 初始化为0</span></span><br><span class="line">        step = <span class="number">0</span></span><br><span class="line">        save_interval = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">        batch_size = <span class="number">50</span></span><br><span class="line">        train_step = <span class="number">3000</span></span><br><span class="line">        <span class="comment"># 记录训练次数, 初始化为0</span></span><br><span class="line">        step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每隔1000步保存模型</span></span><br><span class="line">        <span class="comment">#save_interval = 1000</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># tf.train.Saver是用来保存训练结果的。</span></span><br><span class="line">        <span class="comment"># max_to_keep 用来设置最多保存多少个模型，默认是5</span></span><br><span class="line">        <span class="comment"># 如果保存的模型超过这个值，最旧的模型将被删除</span></span><br><span class="line">        saver = tf.train.Saver(max_to_keep=<span class="number">10</span>)</span><br><span class="line">        ckpt  = tf.train.get_checkpoint_state(ckptfiles)</span><br><span class="line">        merged = tf.summary.merge_all()</span><br><span class="line">        writer = tf.summary.FileWriter(ckptfiles+<span class="string">'graph'</span>,self.sess.graph)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">            saver.restore(self.sess, ckpt.model_checkpoint_path)</span><br><span class="line">            <span class="comment"># 读取网络中的global_step的值，即当前已经训练的次数</span></span><br><span class="line">            step = self.sess.run(self.global_step)</span><br><span class="line">            print(<span class="string">'Continue from'</span>)</span><br><span class="line">            print(<span class="string">'        -&gt; Minibatch update : '</span>, step)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> step &lt; train_step:</span><br><span class="line">            x, label = self.data.train.next_batch(batch_size)</span><br><span class="line">            _, loss = self.sess.run([self.net.train, self.net.loss],</span><br><span class="line">                                    feed_dict=&#123;self.net.x: x, self.net.label: label&#125;)</span><br><span class="line">            step = self.sess.run(self.net.global_step)</span><br><span class="line">            rs=self.sess.run(merged)</span><br><span class="line">            writer.add_summary(rs, step)</span><br><span class="line">            <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">'第%5d步，当前loss：%.2f'</span> % (step, loss))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 模型保存在ckpt文件夹下</span></span><br><span class="line">        <span class="comment"># 模型文件名最后会增加global_step的值，比如1000的模型文件名为 model-1000</span></span><br><span class="line">        <span class="comment">#if step % save_interval == 0:</span></span><br><span class="line">        <span class="comment">#只保存一次模型</span></span><br><span class="line">        saver.save(self.sess, ckptfiles+<span class="string">'model'</span>, global_step=step)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calculate_accuracy</span><span class="params">(self)</span>:</span></span><br><span class="line">        test_x = self.data.test.images</span><br><span class="line">        test_label = self.data.test.labels</span><br><span class="line">        accuracy = self.sess.run(self.net.accuracy,</span><br><span class="line">                                 feed_dict=&#123;self.net.x: test_x, self.net.label: test_label&#125;)</span><br><span class="line">        print(<span class="string">"准确率: %.2f，共测试了%d张图片 "</span> % (accuracy, len(test_label)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    app = TrainMnistLeNet()</span><br><span class="line">    app.trainMnist()</span><br><span class="line">    app.calculate_accuracy()</span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;这个步骤其实比较简单，就是根据数据对整个网络的输入和输出进行实例化操作，在我的代码中是训练的Mnist数据，所以定义输入的变量的28*28的数据，结果为10个数字，然后获取数据进行训练，由于Mnist数据的解析和处理都在tensorflow的example中被处理了，在处理过程中就省略了这个过程，实际上应该定义一个类专门对数据进行处理和优化。</p>
</div><div class="tags"><a href="/tags/tensorflow学习/">tensorflow学习</a></div><div class="post-nav"><a class="pre" href="/2018/08/22/tensorflow-二十八弹/">tensorflow-二十八弹</a><a class="next" href="/2018/07/22/RPC（共线条件方程）校正迭代方法分析/">RPC（共线条件方程）校正迭代方法分析</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'true' == true ? true : false;
var verify = 'true' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'uHNJtTxLkcGm3VRtuRGk53hb-gzGzoHsz',
  appKey:'h8s1QFO2dLQ62H0axpKB6WnD',
  placeholder:'说点啥吧...',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"><input type="hidden" name="si" value="http://www.wuweiblog.com"><input name="tn" type="hidden" value="bds"><input name="cl" type="hidden" value="3"><input name="ct" type="hidden" value="2097152"><input name="s" type="hidden" value="on"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/书评/">书评</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/图像处理/">图像处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/学习/">学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/小说/">小说</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/影评/">影评</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学/">数学</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/游戏/">游戏</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/点云处理/">点云处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随感/">随感</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/ArcGIS，前端开发/" style="font-size: 15px;">ArcGIS，前端开发</a> <a href="/tags/ArcGIS环境配置/" style="font-size: 15px;">ArcGIS环境配置</a> <a href="/tags/ArcGIS开发/" style="font-size: 15px;">ArcGIS开发</a> <a href="/tags/开发/" style="font-size: 15px;">开发</a> <a href="/tags/linux-学习/" style="font-size: 15px;">linux 学习</a> <a href="/tags/学习/" style="font-size: 15px;">学习</a> <a href="/tags/数学/" style="font-size: 15px;">数学</a> <a href="/tags/图像处理数学原理/" style="font-size: 15px;">图像处理数学原理</a> <a href="/tags/系统架构-学习/" style="font-size: 15px;">系统架构 学习</a> <a href="/tags/效率/" style="font-size: 15px;">效率</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/机器学习，图像处理/" style="font-size: 15px;">机器学习，图像处理</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/tensorflow学习/" style="font-size: 15px;">tensorflow学习</a> <a href="/tags/随感/" style="font-size: 15px;">随感</a> <a href="/tags/Mary-and-Max，影评/" style="font-size: 15px;">Mary and Max，影评</a> <a href="/tags/沉默的大多数，书评/" style="font-size: 15px;">沉默的大多数，书评</a> <a href="/tags/断舍离，书评/" style="font-size: 15px;">断舍离，书评</a> <a href="/tags/雪中悍刀行-书评/" style="font-size: 15px;">雪中悍刀行,书评</a> <a href="/tags/呼兰河传-书评/" style="font-size: 15px;">呼兰河传,书评</a> <a href="/tags/将夜-书评/" style="font-size: 15px;">将夜,书评</a> <a href="/tags/中国经济2019-时间的答案/" style="font-size: 15px;">中国经济2019,时间的答案</a> <a href="/tags/未来简史-书评/" style="font-size: 15px;">未来简史,书评</a> <a href="/tags/潜规则-书评/" style="font-size: 15px;">潜规则,书评</a> <a href="/tags/图像处理/" style="font-size: 15px;">图像处理</a> <a href="/tags/你好疯子，影评/" style="font-size: 15px;">你好疯子，影评</a> <a href="/tags/熊镇-书评/" style="font-size: 15px;">熊镇,书评</a> <a href="/tags/openMVG-openMVS学习/" style="font-size: 15px;">openMVG openMVS学习</a> <a href="/tags/喜剧之王，影评/" style="font-size: 15px;">喜剧之王，影评</a> <a href="/tags/The-Legend-of-1900/" style="font-size: 15px;">The Legend of 1900</a> <a href="/tags/随感，毕业/" style="font-size: 15px;">随感，毕业</a> <a href="/tags/随感-摄影测量/" style="font-size: 15px;">随感-摄影测量</a> <a href="/tags/校正方法，控制点，光束法平差/" style="font-size: 15px;">校正方法，控制点，光束法平差</a> <a href="/tags/linux学习/" style="font-size: 15px;">linux学习</a> <a href="/tags/月亮与六便士/" style="font-size: 15px;">月亮与六便士</a> <a href="/tags/电影十二公民/" style="font-size: 15px;">电影十二公民</a> <a href="/tags/V字仇杀队-浪潮，影评/" style="font-size: 15px;">V字仇杀队,浪潮，影评</a> <a href="/tags/小说/" style="font-size: 15px;">小说</a> <a href="/tags/随感－代码重构/" style="font-size: 15px;">随感－代码重构</a> <a href="/tags/随感，死亡/" style="font-size: 15px;">随感，死亡</a> <a href="/tags/遗愿清单，影评/" style="font-size: 15px;">遗愿清单，影评</a> <a href="/tags/指环王，这个杀手不太冷/" style="font-size: 15px;">指环王，这个杀手不太冷</a> <a href="/tags/R-学习/" style="font-size: 15px;">R 学习</a> <a href="/tags/点云处理/" style="font-size: 15px;">点云处理</a> <a href="/tags/狗子日记/" style="font-size: 15px;">狗子日记</a> <a href="/tags/爱乐之城，影评/" style="font-size: 15px;">爱乐之城，影评</a> <a href="/tags/一个叫欧维的男人决定去死，书评/" style="font-size: 15px;">一个叫欧维的男人决定去死，书评</a> <a href="/tags/星际穿越，影评/" style="font-size: 15px;">星际穿越，影评</a> <a href="/tags/图像处理的数学原理/" style="font-size: 15px;">图像处理的数学原理</a> <a href="/tags/社交网络，影评/" style="font-size: 15px;">社交网络，影评</a> <a href="/tags/共产党宣言/" style="font-size: 15px;">共产党宣言</a> <a href="/tags/秒速五厘米/" style="font-size: 15px;">秒速五厘米</a> <a href="/tags/海涛之声，影评/" style="font-size: 15px;">海涛之声，影评</a> <a href="/tags/白日梦想家，影评/" style="font-size: 15px;">白日梦想家，影评</a> <a href="/tags/饥荒/" style="font-size: 15px;">饥荒</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2021/01/31/社会与资本/">社会与资本</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/25/有那么一瞬间/">有那么一瞬间</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/06/死亡记录/">死亡记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/06/不读书-九/">不读书(九)</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/16/挣扎/">挣扎</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/02/点到三维空间直线距离计算以向量方式计算/">点到三维空间直线距离计算以向量方式计算</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/30/ArcGIS-结合-WebGL动态渲染1/">ArcGIS 结合 WebGL动态渲染1</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/30/狗子日记十一月四号/">狗子日记十一月四号</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/18/点云处理总结/">点云处理总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/13/关于方向/">关于方向</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/RemoteSensingFrank" title="Github" target="_blank">Github</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">吴蔚.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>