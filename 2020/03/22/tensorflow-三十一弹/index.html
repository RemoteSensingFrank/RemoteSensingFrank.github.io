<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="随感，遥感，机器学习....想到什么写什么"><title>tensorflow-三十一弹 | 吴蔚</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">tensorflow-三十一弹</h1><a id="logo" href="/.">吴蔚</a><p class="description">生命不息，折腾不止！</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">tensorflow-三十一弹</h1><div class="post-meta">Mar 22, 2020<span> | </span><span class="category"><a href="/categories/学习/">学习</a></span></div><a class="disqus-comment-count" href="/2020/03/22/tensorflow-三十一弹/#vcomment"><span class="valine-comment-count" data-xid="/2020/03/22/tensorflow-三十一弹/"></span><span> 条评论</span></a><div class="post-content"><p>&nbsp;&nbsp;&nbsp;&nbsp;前一段时间熟悉了一下tensorflow2.0以及kersa，然后通过mnist数据集构建了一个简单的深度网络进行了学习，基于上一弹的基础我们来进行一些更加深入的学习，数据集同样是采用mnist数据集，我们来训练一个GAN网络，首先我们对GAN的原理进行分析：</p>
<h2 id="GAN原理分析"><a href="#GAN原理分析" class="headerlink" title="GAN原理分析"></a>GAN原理分析</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;GAN, Generative Adversarial Networks又被称为生成对抗网络<a href="#refer-anchor-1"><sup>1</sup></a>，在这个网络模型中至少需要两个部分，分别成为生成器和识别器，其中生成器主要作用在于根据一个随机输入生成需要生成的对象，识别器可以i认为就是一个简单的神经网络，对生成器生成的数据进行识别。在此过程中需要明确的是代价函数，针对生成器和识别器我们都需要指定代价函数，具体的函数形式我们后续再讨论，首先我们先讨论一下生成器与识别器的模式。</p>
<h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;实际上生成器可以简单的理解为一个分布函数，只是这个分布函数的参数是一个深度神经网络，根据一个输入以及目标label得到一个确定的输出，具体代码为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">acgan_generator</span><span class="params">()</span>:</span></span><br><span class="line">    model = Sequential()</span><br><span class="line"></span><br><span class="line">    model.add(layers.Dense(<span class="number">128</span> * <span class="number">7</span> * <span class="number">7</span>, activation=<span class="string">"relu"</span>, input_dim=<span class="number">100</span>))</span><br><span class="line">    model.add(layers.Reshape((<span class="number">7</span>, <span class="number">7</span>, <span class="number">128</span>)))</span><br><span class="line">    model.add(layers.BatchNormalization(momentum=<span class="number">0.8</span>))</span><br><span class="line">    model.add(layers.UpSampling2D())</span><br><span class="line">    model.add(layers.Conv2D(<span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="string">"same"</span>))</span><br><span class="line">    model.add(layers.Activation(<span class="string">"relu"</span>))</span><br><span class="line">    model.add(layers.BatchNormalization(momentum=<span class="number">0.8</span>))</span><br><span class="line">    model.add(layers.UpSampling2D())</span><br><span class="line">    model.add(layers.Conv2D(<span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="string">"same"</span>))</span><br><span class="line">    model.add(layers.Activation(<span class="string">"relu"</span>))</span><br><span class="line">    model.add(layers.BatchNormalization(momentum=<span class="number">0.8</span>))</span><br><span class="line">    model.add(layers.Conv2D(<span class="number">1</span>, kernel_size=<span class="number">3</span>, padding=<span class="string">'same'</span>))</span><br><span class="line">    model.add(layers.Activation(<span class="string">"tanh"</span>))</span><br><span class="line"></span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    noise = layers.Input(shape=(<span class="number">100</span>,))</span><br><span class="line">    label = layers.Input(shape=(<span class="number">1</span>,), dtype=<span class="string">'int32'</span>)</span><br><span class="line">    label_embedding = layers.Flatten()(layers.Embedding(<span class="number">10</span>, <span class="number">100</span>)(label))</span><br><span class="line"></span><br><span class="line">    model_input = layers.multiply([noise, label_embedding])</span><br><span class="line">    img = model(model_input)</span><br><span class="line">    <span class="comment">#将模型输出</span></span><br><span class="line">    keras.utils.plot_model(model, to_file=<span class="string">'./data/2_Generator.png'</span>, show_shapes=<span class="keyword">True</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.keras.Model([noise, label], img)</span><br></pre></td></tr></table></figure></p>
<p>这个生成器的结构为：<br><img src="https://blogimage-1251632003.cos.ap-guangzhou.myqcloud.com/2_Generator.png" alt="生成器"><br>为了简单起见我们结合代码与程序结构同时进行分析，首先我们的生成器是一个随机的输入向量，这个向量是一个100维的随机向量，同时输入一个label值，通过label值来标识需要模拟哪个数值（mnist只有10个值），这个100维向量通过神经网络转换维128<em>7</em>7的向量，步骤包括：</p>
<ul>
<li>向量转换为二维-&gt;归一化-&gt;向上采样维128<em>（14</em>14）的向量-&gt;卷积操作-&gt;激活函数-&gt;归一化-&gt;向上采样维64<em>（28</em>28）的向量-&gt;卷积操作-&gt;激活函数-&gt;归一化为1&amp;（27*28）的向量-&gt;卷积操作-&gt;激活函数</li>
</ul>
<p>最后得到一个生成的28<em>28的手写数字以及输入的待识别的标识，函数最后将构建的模型输出，实际上生成器就完成了，简单的说就是根据一个随机的输入值构建了一个生成28</em>28大小的影像。</p>
<h3 id="识别器"><a href="#识别器" class="headerlink" title="识别器"></a>识别器</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;实际上识别器的主要作用在于识别图像是否由生成器生成，在我们这个目标中识别器的作用是识别通过生成器生成的手写数字是否为对应的数字，识别器的具体代码为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">acgan_discriminator</span><span class="params">()</span>:</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(layers.Conv2D(<span class="number">16</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">2</span>, input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>), padding=<span class="string">"same"</span>))</span><br><span class="line">    model.add(layers.LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(layers.Dropout(<span class="number">0.25</span>))</span><br><span class="line">    model.add(layers.Conv2D(<span class="number">32</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="string">"same"</span>))</span><br><span class="line">    model.add(layers.ZeroPadding2D(padding=((<span class="number">0</span>,<span class="number">1</span>),(<span class="number">0</span>,<span class="number">1</span>))))</span><br><span class="line">    model.add(layers.LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(layers.Dropout(<span class="number">0.25</span>))</span><br><span class="line">    model.add(layers.BatchNormalization(momentum=<span class="number">0.8</span>))</span><br><span class="line">    model.add(layers.Conv2D(<span class="number">64</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="string">"same"</span>))</span><br><span class="line">    model.add(layers.LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(layers.Dropout(<span class="number">0.25</span>))</span><br><span class="line">    model.add(layers.BatchNormalization(momentum=<span class="number">0.8</span>))</span><br><span class="line">    model.add(layers.Conv2D(<span class="number">128</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">"same"</span>))</span><br><span class="line">    model.add(layers.LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(layers.Dropout(<span class="number">0.25</span>))</span><br><span class="line"></span><br><span class="line">    model.add(layers.Flatten())</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    img = layers.Input(shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Extract feature representation</span></span><br><span class="line">    features = model(img)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Determine validity and label of the image</span></span><br><span class="line">    validity = layers.Dense(<span class="number">1</span>, activation=<span class="string">"sigmoid"</span>)(features)</span><br><span class="line">    label = layers.Dense(<span class="number">10</span>, activation=<span class="string">"softmax"</span>)(features)</span><br><span class="line">    </span><br><span class="line">    keras.utils.plot_model(model, to_file=<span class="string">'./data/2_Discriminator.png'</span>, show_shapes=<span class="keyword">True</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.keras.Model(img, [validity, label])</span><br></pre></td></tr></table></figure></p>
<p><img src="https://blogimage-1251632003.cos.ap-guangzhou.myqcloud.com/2_Discriminator.png" alt="识别器"><br>识别器可以简单的理解为是一个识别输入的图像是否为对应数组的一个深度网络，其输入是影像，输出是数字的10维向量，对于识别器的识别过程，在以前就多此提到过，在这里没有必要再多提了，通过识别器可以对生成器生成的结果进行识别给出判断结果对生成器进行优化，同时识别器不仅要识别数字结果还需要识别validity，这个标识的主要作用在于标识输入的参数是由生成器提供还是真实数据。</p>
<h3 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(epochs, batch_size=<span class="number">128</span>, sample_interval=<span class="number">10</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Build and compile the discriminator</span></span><br><span class="line">    optimizer = Adam(<span class="number">0.0002</span>, <span class="number">0.5</span>)</span><br><span class="line">    losses = [<span class="string">'binary_crossentropy'</span>, <span class="string">'sparse_categorical_crossentropy'</span>]</span><br><span class="line">    discriminator = acgan_discriminator()</span><br><span class="line">    discriminator.compile(loss=losses,</span><br><span class="line">        optimizer=optimizer,</span><br><span class="line">        metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build the generator</span></span><br><span class="line">    </span><br><span class="line">    generator = acgan_generator()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># The generator takes noise and the target label as input</span></span><br><span class="line">    <span class="comment"># and generates the corresponding digit of that label</span></span><br><span class="line">    noise = layers.Input(shape=(<span class="number">100</span>,))</span><br><span class="line">    label = layers.Input(shape=(<span class="number">1</span>,))</span><br><span class="line">    img = generator([noise, label])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># For the combined model we will only train the generator</span></span><br><span class="line">    discriminator.trainable = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># The discriminator takes generated image as input and determines validity</span></span><br><span class="line">    <span class="comment"># and the label of that image</span></span><br><span class="line">    valid, target_label = discriminator(img)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># The combined model  (stacked generator and discriminator)</span></span><br><span class="line">    <span class="comment"># Trains the generator to fool the discriminator</span></span><br><span class="line">    combined = tf.keras.Model([noise, label], [valid, target_label])</span><br><span class="line">    combined.compile(loss=losses,optimizer=optimizer)</span><br><span class="line">    keras.utils.plot_model(combined, to_file=<span class="string">'./data/2_Combined.png'</span>, show_shapes=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load the dataset</span></span><br><span class="line">    (X_train, y_train), (_, _) = load_mnist_data()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Configure inputs</span></span><br><span class="line">    X_train = (X_train.astype(np.float32) - <span class="number">127.5</span>) / <span class="number">127.5</span></span><br><span class="line">    X_train = np.expand_dims(X_train, axis=<span class="number">3</span>)</span><br><span class="line">    y_train = y_train.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Adversarial ground truths</span></span><br><span class="line">    valid = np.ones((batch_size, <span class="number">1</span>))</span><br><span class="line">    fake = np.zeros((batch_size, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line">        <span class="comment">#  Train Discriminator</span></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Select a random batch of images</span></span><br><span class="line">        idx = np.random.randint(<span class="number">0</span>, X_train.shape[<span class="number">0</span>], batch_size)</span><br><span class="line">        imgs = X_train[idx]</span><br><span class="line">        <span class="comment"># Image labels. 0-9 </span></span><br><span class="line">        img_labels = y_train[idx]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Sample noise as generator input</span></span><br><span class="line">        noise = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (batch_size, <span class="number">100</span>))</span><br><span class="line">        <span class="comment"># The labels of the digits that the generator tries to create an</span></span><br><span class="line">        <span class="comment"># image representation of</span></span><br><span class="line">        sampled_labels = np.random.randint(<span class="number">0</span>, <span class="number">10</span>, (batch_size, <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># Generate a half batch of new images</span></span><br><span class="line">        gen_imgs = generator.predict([noise, sampled_labels])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Train the discriminator</span></span><br><span class="line">        d_loss_real = discriminator.train_on_batch(imgs, [valid, img_labels])</span><br><span class="line">        d_loss_fake = discriminator.train_on_batch(gen_imgs, [fake, sampled_labels])</span><br><span class="line">        d_loss = <span class="number">0.5</span> * np.add(d_loss_real, d_loss_fake)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line">        <span class="comment">#  Train Generator</span></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Train the generator</span></span><br><span class="line">        g_loss = combined.train_on_batch([noise, sampled_labels], [valid, sampled_labels])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Plot the progress</span></span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"%d [D loss: %f, acc.: %.2f%%, op_acc: %.2f%%] [G loss: %f]"</span> % (epoch, d_loss[<span class="number">0</span>], <span class="number">100</span>*d_loss[<span class="number">3</span>], <span class="number">100</span>*d_loss[<span class="number">4</span>], g_loss[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># If at save interval =&gt; save generated image samples</span></span><br><span class="line">        <span class="keyword">if</span> epoch % sample_interval == <span class="number">0</span>:</span><br><span class="line">            <span class="comment">#save_model(generator,discriminator)</span></span><br><span class="line">            sample_images(epoch,generator)</span><br><span class="line">    save_model(generator,discriminator)</span><br></pre></td></tr></table></figure>
<p>代码也不是很难，主要过程在于训练的过程，在训练的过程中我们通过真实数据与fake数据的交替训练对生成器和识别器进行训练，识别器需要识别的结<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">d_loss_real = discriminator.train_on_batch(imgs, [valid, img_labels])</span><br><span class="line">d_loss_fake = discriminator.train_on_batch(gen_imgs, [fake, sampled_labels])</span><br><span class="line">d_loss = <span class="number">0.5</span> * np.add(d_loss_real, d_loss_fake)</span><br></pre></td></tr></table></figure></p>
<p>以上代码就是识别器识别的过程，实际上我们识别器需要保证识别的label和vaild同时准确才行，所以识别的损失函数为识别真实数据的损失函数与生成器生成数据的损失函数；在完成识别器训练后就需要对生成器进行训练，对生成器的训练过程实际上损失函数就是输入的noise以及需要识别的数字，然后通过识别器能够识别出是是否是生成器生成的数据以及是否为给定的数值，据此对生成器进行训练，通过交替训练识别器与生成器达到最后生成器能够进行最好的识别的效果。</p>
<h3 id="结果与讨论"><a href="#结果与讨论" class="headerlink" title="结果与讨论"></a>结果与讨论</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;通过以上过程可以得到一个稳定的生成器与识别器，实际上GAN最大的作用还是在于训练生成器，使得生成器生成的数据能够最佳拟合真实数据，达到模拟仿真的目的。同时GAN也被广泛的应用于图像修复，图像生成，音乐生成，围棋<a href="&quot;refer-anchor-2&quot;"><sup>2</sup></a><a href="&quot;refer-anchor-3&quot;"><sup>3</sup></a><a href="&quot;refer-anchor-4&quot;"><sup>4</sup></a>等领域，实际上GAN的出现使得计算器自学习能力向前迈进了一大步，下面展示通过GAN训练的手写数字模拟的效果：<br><img src="https://blogimage-1251632003.cos.ap-guangzhou.myqcloud.com/2_GANResult.png" alt="GAN模拟手写数据结果"><br>上图为模拟的结果，模拟的数字为1，文件名为迭代的次数，每次迭代的batch大小为100，可以看出迭代次数小的时候模拟结果比较差，当迭代次数增加，生成器效果慢慢编号，最后随着迭代次数的增加，生成器生成的数据已经能够很好的模拟手写数字的真实数据了。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><div id="refer-anchor-1"></div></p>
<ul>
<li>[1] Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,<br>Ozair, S., Courville, A., and Bengio, Y. (2014b). Generative adversarial networks. In NIPS’2014 .<div id="refer-anchor-2"></div></li>
<li>[2] Yijun Li, Sifei Liu, Jimei Yang,et.al. Generative Face Completion[C]// IEEE Conference on Computer Vision &amp; Pattern Recognition. IEEE, 2017.<div id="refer-anchor-3"></div></li>
<li>[3] Jean-Marc Valin, Jan Skoglund. LPCNET: Improving Neural Speech Synthesis through Linear Prediction[C]// Icassp IEEE International Conference on Acoustics. IEEE, 2019.<div id="refer-anchor-4"></div></li>
<li>[4] Jim X. Chen. The Evolution of Computing: AlphaGo[J]. Computing in Science &amp; Engineering, 2016, 18(4):4-7.</li>
</ul>
</div><div class="tags"><a href="/tags/tensorflow学习/">tensorflow学习</a></div><div class="post-nav"><a class="pre" href="/2020/03/22/关于openSFM的学习/">关于openSFM代码学习</a><a class="next" href="/2020/03/03/tensorflow-三十弹/">tensorflow-三十弹</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'true' == true ? true : false;
var verify = 'true' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'uHNJtTxLkcGm3VRtuRGk53hb-gzGzoHsz',
  appKey:'h8s1QFO2dLQ62H0axpKB6WnD',
  placeholder:'说点啥吧...',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"><input type="hidden" name="si" value="https://www.wuweiblog.com"><input name="tn" type="hidden" value="bds"><input name="cl" type="hidden" value="3"><input name="ct" type="hidden" value="2097152"><input name="s" type="hidden" value="on"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/书评/">书评</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/图像处理/">图像处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/学习/">学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/小说/">小说</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/影评/">影评</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学/">数学</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/游戏/">游戏</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/点云处理/">点云处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随感/">随感</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/ArcGIS，前端开发/" style="font-size: 15px;">ArcGIS，前端开发</a> <a href="/tags/ArcGIS开发/" style="font-size: 15px;">ArcGIS开发</a> <a href="/tags/ArcGIS环境配置/" style="font-size: 15px;">ArcGIS环境配置</a> <a href="/tags/开发/" style="font-size: 15px;">开发</a> <a href="/tags/linux-学习/" style="font-size: 15px;">linux 学习</a> <a href="/tags/数学/" style="font-size: 15px;">数学</a> <a href="/tags/图像处理数学原理/" style="font-size: 15px;">图像处理数学原理</a> <a href="/tags/学习/" style="font-size: 15px;">学习</a> <a href="/tags/系统架构-学习/" style="font-size: 15px;">系统架构 学习</a> <a href="/tags/效率/" style="font-size: 15px;">效率</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/tensorflow学习/" style="font-size: 15px;">tensorflow学习</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/机器学习，图像处理/" style="font-size: 15px;">机器学习，图像处理</a> <a href="/tags/Mary-and-Max，影评/" style="font-size: 15px;">Mary and Max，影评</a> <a href="/tags/断舍离，书评/" style="font-size: 15px;">断舍离，书评</a> <a href="/tags/沉默的大多数，书评/" style="font-size: 15px;">沉默的大多数，书评</a> <a href="/tags/随感/" style="font-size: 15px;">随感</a> <a href="/tags/雪中悍刀行-书评/" style="font-size: 15px;">雪中悍刀行,书评</a> <a href="/tags/将夜-书评/" style="font-size: 15px;">将夜,书评</a> <a href="/tags/中国经济2019-时间的答案/" style="font-size: 15px;">中国经济2019,时间的答案</a> <a href="/tags/呼兰河传-书评/" style="font-size: 15px;">呼兰河传,书评</a> <a href="/tags/熊镇-书评/" style="font-size: 15px;">熊镇,书评</a> <a href="/tags/潜规则-书评/" style="font-size: 15px;">潜规则,书评</a> <a href="/tags/图像处理/" style="font-size: 15px;">图像处理</a> <a href="/tags/未来简史-书评/" style="font-size: 15px;">未来简史,书评</a> <a href="/tags/你好疯子，影评/" style="font-size: 15px;">你好疯子，影评</a> <a href="/tags/openMVG-openMVS学习/" style="font-size: 15px;">openMVG openMVS学习</a> <a href="/tags/喜剧之王，影评/" style="font-size: 15px;">喜剧之王，影评</a> <a href="/tags/The-Legend-of-1900/" style="font-size: 15px;">The Legend of 1900</a> <a href="/tags/随感，毕业/" style="font-size: 15px;">随感，毕业</a> <a href="/tags/随感-摄影测量/" style="font-size: 15px;">随感-摄影测量</a> <a href="/tags/校正方法，控制点，光束法平差/" style="font-size: 15px;">校正方法，控制点，光束法平差</a> <a href="/tags/linux学习/" style="font-size: 15px;">linux学习</a> <a href="/tags/月亮与六便士/" style="font-size: 15px;">月亮与六便士</a> <a href="/tags/电影十二公民/" style="font-size: 15px;">电影十二公民</a> <a href="/tags/小说/" style="font-size: 15px;">小说</a> <a href="/tags/随感，死亡/" style="font-size: 15px;">随感，死亡</a> <a href="/tags/V字仇杀队-浪潮，影评/" style="font-size: 15px;">V字仇杀队,浪潮，影评</a> <a href="/tags/随感－代码重构/" style="font-size: 15px;">随感－代码重构</a> <a href="/tags/R-学习/" style="font-size: 15px;">R 学习</a> <a href="/tags/遗愿清单，影评/" style="font-size: 15px;">遗愿清单，影评</a> <a href="/tags/指环王，这个杀手不太冷/" style="font-size: 15px;">指环王，这个杀手不太冷</a> <a href="/tags/点云处理/" style="font-size: 15px;">点云处理</a> <a href="/tags/爱乐之城，影评/" style="font-size: 15px;">爱乐之城，影评</a> <a href="/tags/狗子日记/" style="font-size: 15px;">狗子日记</a> <a href="/tags/图像处理的数学原理/" style="font-size: 15px;">图像处理的数学原理</a> <a href="/tags/星际穿越，影评/" style="font-size: 15px;">星际穿越，影评</a> <a href="/tags/一个叫欧维的男人决定去死，书评/" style="font-size: 15px;">一个叫欧维的男人决定去死，书评</a> <a href="/tags/社交网络，影评/" style="font-size: 15px;">社交网络，影评</a> <a href="/tags/共产党宣言/" style="font-size: 15px;">共产党宣言</a> <a href="/tags/秒速五厘米/" style="font-size: 15px;">秒速五厘米</a> <a href="/tags/海涛之声，影评/" style="font-size: 15px;">海涛之声，影评</a> <a href="/tags/白日梦想家，影评/" style="font-size: 15px;">白日梦想家，影评</a> <a href="/tags/饥荒/" style="font-size: 15px;">饥荒</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2021/01/31/社会与资本/">社会与资本</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/01/11/你好2021/">你好2021</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/25/有那么一瞬间/">有那么一瞬间</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/06/死亡记录/">死亡记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/06/不读书-九/">不读书(九)</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/16/挣扎/">挣扎</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/02/点到三维空间直线距离计算以向量方式计算/">点到三维空间直线距离计算以向量方式计算</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/30/ArcGIS-结合-WebGL动态渲染1/">ArcGIS 结合 WebGL动态渲染1</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/30/狗子日记十一月四号/">狗子日记十一月四号</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/18/点云处理总结/">点云处理总结</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/RemoteSensingFrank" title="Github" target="_blank">Github</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">吴蔚.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>